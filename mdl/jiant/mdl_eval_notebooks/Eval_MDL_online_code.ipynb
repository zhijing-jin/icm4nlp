{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some info about tasks we will need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_examples = { 'pos': 2070382, 'dep': 203919, 'coref': 207830, 'srl': 598983, 'ner': 128738, 'nonterm': 1851590, 'relsem': 6851}\n",
    "\n",
    "num_labels = { 'pos': 48, 'dep': 49, 'coref': 2, 'srl': 66, 'ner': 18, 'nonterm': 30, 'relsem': 19}\n",
    "\n",
    "full_task_name = {'pos': 'pos-ontonotes', 'nonterm': 'nonterminal-ontonotes', \n",
    "                  'dep': 'dep-ud-ewt', 'srl': 'srl-ontonotes',\n",
    "                  'coref': 'coref-ontonotes', 'relsem': 'rel-semeval','ner': 'ner-ontonotes'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Directory with your experiments:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_with_experiments = '<insert your dir>'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading logs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For example, let's look at POS, layer 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "task = 'pos'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the experiment folder you will find a file with the test scores for models trained on each portion. In the folder for the last portion (10th) will be information on all portions. The last portion is the whole training dataset: this information is not used when evaluating online codelength, but we will use it to get test accuracy: this is accuracy of the standard probe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "online_report = pickle.load(open(dir_with_experiments + 'pos_online_layer0/run1/online_portion_10/online_coding.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy (standard probe):  91.28\n"
     ]
    }
   ],
   "source": [
    "print(\"Test accuracy (standard probe): \",\n",
    "      round(online_report[-1]['edges-{}_acc_test'.format(full_task_name[task])] * 100, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Codelength"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "online_report = pickle.load(open(dir_with_experiments + 'pos_online_layer0/run1/online_portion_10/online_coding.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Uniform codelength"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "uniform_codelength = num_examples[task] * np.log2(num_labels[task])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Online codelength"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that for MDL you __do not need__ the last portion - this is model trained on all data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_portion_size = num_examples[task] - sum([el['edges-{}_num_examples_dev_portion_online'.format(full_task_name[task])] for el in online_report[:-1]])\n",
    "\n",
    "online_codelength = first_portion_size * np.log2(num_labels[task]) +\\\n",
    "            sum([el['edges-{}_sumloss_dev_portion_online'.format(full_task_name[task])]  for el in online_report[:-1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Online codelength: 461.55 kbits\n",
      "Compression: 24.47 \n"
     ]
    }
   ],
   "source": [
    "print(\"Online codelength: {} kbits\".format(round(online_codelength / 1024, 2)))\n",
    "print(\"Compression: {} \".format(round(uniform_codelength / online_codelength, 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
